{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5e2a348",
   "metadata": {},
   "source": [
    "# Kaggle Notebook: GIS-based Legality + YOLO Fine-tuning\n",
    "\n",
    "This notebook helps you:\n",
    "- Install dependencies on Kaggle\n",
    "- Load/export dataset from a private Kaggle Dataset\n",
    "- Optionally fine-tune YOLO on your 5-class encroachment labels\n",
    "- Visualize overlays and run batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d3f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Set Up Environment and Dependencies\n",
    "!pip -q install ultralytics shapely pyproj geopandas folium kaggle --upgrade\n",
    "\n",
    "import os, sys, json, platform\n",
    "import torch\n",
    "print({\n",
    "    'python': sys.version,\n",
    "    'platform': platform.platform(),\n",
    "    'cuda_available': torch.cuda.is_available(),\n",
    "    'device_count': torch.cuda.device_count(),\n",
    "})\n",
    "\n",
    "# Capture requirements for reproducibility (optional)\n",
    "!pip freeze | grep -E 'ultralytics|shapely|pyproj|geopandas|folium|torch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28787e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Define Classes, Subclasses, and Config\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict, Any\n",
    "import yaml\n",
    "\n",
    "class TopClass(str, Enum):\n",
    "    Permanent_Legal = 'Permanent_Legal'\n",
    "    Permanent_Illegal = 'Permanent_Illegal'\n",
    "    Temporary_Legal = 'Temporary_Legal'\n",
    "    Temporary_Illegal = 'Temporary_Illegal'\n",
    "    Natural_Area = 'Natural_Area'\n",
    "\n",
    "@dataclass\n",
    "class Attributes:\n",
    "    permanence: Optional[str] = None  # 'permanent' | 'temporary'\n",
    "    zone: Optional[str] = None        # 'river_buffer'| 'road_footpath' | 'vending_zone' | 'festival_zone' | 'none'\n",
    "    permit_status: Optional[str] = None  # 'approved' | 'unapproved' | 'unknown'\n",
    "    area_type: Optional[str] = None   # 'natural_area' | 'built'\n",
    "    structure_type: Optional[str] = None\n",
    "\n",
    "# Load ontology rules (optional)\n",
    "ONTOLOGY_PATH = '/kaggle/working/ontology.yaml'\n",
    "\n",
    "ontology_fallback = {\n",
    "    'class_ids': {\n",
    "        'Permanent_Legal': 0, 'Permanent_Illegal': 1, 'Temporary_Legal': 2, 'Temporary_Illegal': 3, 'Natural_Area': 4\n",
    "    }\n",
    "}\n",
    "\n",
    "def load_ontology(path: str):\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            return yaml.safe_load(f)\n",
    "    except Exception:\n",
    "        return ontology_fallback\n",
    "\n",
    "ontology = load_ontology(ONTOLOGY_PATH)\n",
    "print('Ontology loaded:', list(ontology.get('class_ids', {}).keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6333084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Load or Synthesize GIS Polygons\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# Try to load from dataset if provided, else synthesize simple boxes\n",
    "DATASET_DIR = '/kaggle/input/YOUR_DATASET_NAME/dataset'  # TODO: set your Kaggle dataset path\n",
    "GEOJSON_PATH = os.path.join(DATASET_DIR, 'zones.geojson')\n",
    "\n",
    "if os.path.exists(GEOJSON_PATH):\n",
    "    zones_gdf = gpd.read_file(GEOJSON_PATH)\n",
    "    assert zones_gdf.crs, 'zones.geojson missing CRS'\n",
    "else:\n",
    "    # Synthesize example zones in EPSG:4326\n",
    "    zones = [\n",
    "        ('river_buffer', Polygon([(75.75, 23.10), (75.80, 23.10), (75.80, 23.15), (75.75, 23.15)])),\n",
    "        ('road_footpath', Polygon([(75.70, 23.08), (75.85, 23.08), (75.85, 23.09), (75.70, 23.09)])),\n",
    "        ('vending_zone', Polygon([(75.77, 23.11), (75.78, 23.11), (75.78, 23.12), (75.77, 23.12)])),\n",
    "        ('festival_zone', Polygon([(75.79, 23.12), (75.80, 23.12), (75.80, 23.13), (75.79, 23.13)])),\n",
    "        ('natural_area', Polygon([(75.72, 23.13), (75.74, 23.13), (75.74, 23.16), (75.72, 23.16)])),\n",
    "    ]\n",
    "    zones_gdf = gpd.GeoDataFrame({'name':[n for n,_ in zones]}, geometry=[g for _,g in zones], crs='EPSG:4326')\n",
    "\n",
    "zones_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2738fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Load or Synthesize Detected Objects with Geo Coordinates\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "DETECTIONS_CSV = os.path.join(DATASET_DIR, 'detections.csv')\n",
    "if os.path.exists(DETECTIONS_CSV):\n",
    "    df = pd.read_csv(DETECTIONS_CSV)\n",
    "else:\n",
    "    import numpy as np\n",
    "    rng = np.random.default_rng(42)\n",
    "    N = 200\n",
    "    lons = rng.uniform(75.70, 75.82, N)\n",
    "    lats = rng.uniform(23.08, 23.16, N)\n",
    "    structure_type = rng.choice(['permanent', 'temporary'], N)\n",
    "    permit = rng.choice(['approved', 'unapproved', 'unknown'], N, p=[0.2, 0.4, 0.4])\n",
    "    df = pd.DataFrame({'id': range(N), 'lon': lons, 'lat': lats, 'permanence': structure_type, 'permit_status': permit})\n",
    "\n",
    "points_gdf = gpd.GeoDataFrame(df, geometry=[Point(xy) for xy in zip(df['lon'], df['lat'])], crs='EPSG:4326')\n",
    "points_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2198d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Geospatial Overlay and Rule Engine\n",
    "# Priority: river_buffer -> road_footpath -> vending/festival -> natural_area -> none\n",
    "\n",
    "# Spatial join\n",
    "joined = gpd.sjoin(points_gdf, zones_gdf.rename(columns={'name':'zone'}), how='left', predicate='within')\n",
    "joined['zone'] = joined['zone'].fillna('none')\n",
    "\n",
    "# Apply rule engine\n",
    "\n",
    "def decide_legality(row):\n",
    "    zone = row['zone']\n",
    "    perm = row.get('permanence', 'temporary')\n",
    "    permit = row.get('permit_status', 'unknown')\n",
    "\n",
    "    if zone == 'natural_area':\n",
    "        return TopClass.Natural_Area.value\n",
    "    if zone in ('river_buffer', 'road_footpath'):\n",
    "        return TopClass.Permanent_Illegal.value if perm == 'permanent' else TopClass.Temporary_Illegal.value\n",
    "    if zone in ('vending_zone', 'festival_zone'):\n",
    "        if permit == 'approved':\n",
    "            return TopClass.Temporary_Legal.value if perm == 'temporary' else TopClass.Permanent_Legal.value\n",
    "        else:\n",
    "            return TopClass.Temporary_Illegal.value if perm == 'temporary' else TopClass.Permanent_Illegal.value\n",
    "    # outside all zones -> default by permanence + permit\n",
    "    if perm == 'permanent':\n",
    "        return TopClass.Permanent_Legal.value if permit == 'approved' else TopClass.Permanent_Illegal.value\n",
    "    else:\n",
    "        return TopClass.Temporary_Illegal.value\n",
    "\n",
    "joined['top_class'] = joined.apply(decide_legality, axis=1)\n",
    "joined[['id','zone','permanence','permit_status','top_class']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ca402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Label Encoding and Dataset Assembly\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cls2id = ontology.get('class_ids', {c.value:i for i,c in enumerate(TopClass)})\n",
    "joined['target_id'] = joined['top_class'].map(cls2id)\n",
    "\n",
    "features = joined[['lon','lat']].copy()\n",
    "features['zone'] = joined['zone']\n",
    "X = pd.get_dummies(features, columns=['zone'])\n",
    "y = joined['target_id']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "out_dir = '/kaggle/working/data'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "joined.to_parquet(os.path.join(out_dir, 'labeled_points.parquet'))\n",
    "X_train.to_parquet(os.path.join(out_dir, 'X_train.parquet'))\n",
    "X_val.to_parquet(os.path.join(out_dir, 'X_val.parquet'))\n",
    "y_train.to_frame('y').to_parquet(os.path.join(out_dir, 'y_train.parquet'))\n",
    "y_val.to_frame('y').to_parquet(os.path.join(out_dir, 'y_val.parquet'))\n",
    "\n",
    "print('Saved dataset to', out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92ad0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Visualize Polygons and Labeled Objects on a Map\n",
    "import folium\n",
    "\n",
    "center = [joined['lat'].mean(), joined['lon'].mean()]\n",
    "mp = folium.Map(location=center, zoom_start=13)\n",
    "\n",
    "# Add polygons\n",
    "for _, r in zones_gdf.iterrows():\n",
    "    gj = folium.GeoJson(r['geometry'].__geo_interface__, name=r.get('name','zone'))\n",
    "    gj.add_to(mp)\n",
    "\n",
    "# Add points colored by class\n",
    "color_map = {\n",
    "    'Permanent_Legal': 'green',\n",
    "    'Permanent_Illegal': 'red',\n",
    "    'Temporary_Legal': 'blue',\n",
    "    'Temporary_Illegal': 'orange',\n",
    "    'Natural_Area': 'gray'\n",
    "}\n",
    "for _, r in joined.sample(min(len(joined), 200), random_state=42).iterrows():\n",
    "    folium.CircleMarker(location=[r['lat'], r['lon']], radius=3, color=color_map[r['top_class']], fill=True, fill_opacity=0.7).add_to(mp)\n",
    "\n",
    "folium.LayerControl().add_to(mp)\n",
    "mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cccd269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Unit Tests for Overlay Logic (inline)\n",
    "# Simple inline checks; for real projects, export to tests/ and run pytest.\n",
    "\n",
    "# Boundary test: pick a boundary point\n",
    "bpoly = zones_gdf.iloc[0].geometry\n",
    "bpt = bpoly.boundary.interpolate(0.5, normalized=True)\n",
    "bdf = gpd.GeoDataFrame([{'lon': bpt.x, 'lat': bpt.y}], geometry=[bpt], crs='EPSG:4326')\n",
    "res = gpd.sjoin(bdf, zones_gdf.rename(columns={'name':'zone'}), how='left', predicate='within')\n",
    "assert res['zone'].isna().all(), 'Point on boundary should not be within by strict within() predicate'\n",
    "\n",
    "# Overlap priority check (synthetic): ensure river_buffer takes precedence in our rules\n",
    "row = {'zone':'river_buffer','permanence':'temporary','permit_status':'unknown'}\n",
    "assert decide_legality(row) == 'Temporary_Illegal'\n",
    "\n",
    "print('Inline tests passed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Export Dataset and Code to Kaggle (API)\n",
    "# Requires Kaggle credentials. On Kaggle, this is often not needed since we run within the kernel.\n",
    "\n",
    "from pathlib import Path\n",
    "try:\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "    api = KaggleApi(); api.authenticate()\n",
    "    print('Kaggle API authenticated')\n",
    "except Exception as e:\n",
    "    print('Kaggle API not available or not authenticated:', e)\n",
    "\n",
    "# Example: create version if running locally with credentials (skip inside Kaggle kernel)\n",
    "# DATASET_SLUG = 'encroachment-zones-labeled'\n",
    "# owner_slug = '<your-username>'\n",
    "# meta = {\n",
    "#   'title': 'Encroachment GIS Labeled Points',\n",
    "#   'id': f'{owner_slug}/{DATASET_SLUG}',\n",
    "#   'licenses': [{ 'name': 'CC0-1.0' }]\n",
    "# }\n",
    "# with open('/kaggle/working/dataset-metadata.json', 'w') as f:\n",
    "#     json.dump(meta, f, indent=2)\n",
    "# api.dataset_create_version('/kaggle/working', 'Initial version', quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b6d0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Create and Push Kaggle Kernel (Template)\n",
    "# Typically managed via web UI or local Kaggle API. Skipping execution here.\n",
    "print('Kernel push is typically done from local with kaggle CLI. See README for steps.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0489bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) Optional: Fine-tune YOLO on Kaggle\n",
    "from ultralytics import YOLO\n",
    "\n",
    "DATA_YAML = os.path.join(DATASET_DIR, 'data.yaml')\n",
    "print('Using data.yaml:', DATA_YAML)\n",
    "\n",
    "try:\n",
    "    model = YOLO('yolov8n.pt')  # or yolov8s.pt\n",
    "    results = model.train(data=DATA_YAML, epochs=20, imgsz=640, batch=16, patience=10)\n",
    "    model.val()\n",
    "    os.makedirs('/kaggle/working/weights', exist_ok=True)\n",
    "    # Ultralytics saves runs to runs/detect/train*/weights/best.pt\n",
    "    import glob, shutil\n",
    "    bests = sorted(glob.glob('runs/detect/*/weights/best.pt'))\n",
    "    if bests:\n",
    "        best = bests[-1]\n",
    "        shutil.copy(best, '/kaggle/working/weights/best.pt')\n",
    "        print('Saved /kaggle/working/weights/best.pt')\n",
    "except Exception as e:\n",
    "    print('YOLO training skipped or failed:', e)\n",
    "\n",
    "# Show some predictions (if val images available)\n",
    "VAL_DIR = os.path.join(DATASET_DIR, 'images', 'val')\n",
    "if os.path.isdir(VAL_DIR):\n",
    "    try:\n",
    "        preds = model.predict(source=VAL_DIR, conf=0.25, save=True, max_det=200)\n",
    "        print('Predictions saved under runs/detect/predict*')\n",
    "    except Exception as e:\n",
    "        print('Prediction step skipped:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f074d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) Batch Inference Pipeline (CLI-like)\n",
    "import argparse\n",
    "\n",
    "def classify_points_csv(input_csv: str, out_csv: str):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=[Point(xy) for xy in zip(df['lon'], df['lat'])], crs='EPSG:4326')\n",
    "    res = gpd.sjoin(gdf, zones_gdf.rename(columns={'name':'zone'}), how='left', predicate='within')\n",
    "    res['zone'] = res['zone'].fillna('none')\n",
    "    res['top_class'] = res.apply(decide_legality, axis=1)\n",
    "    res.drop(columns=['geometry'], inplace=True)\n",
    "    res.to_csv(out_csv, index=False)\n",
    "    print('Wrote', out_csv)\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "# classify_points_csv('/kaggle/input/some-new-detections.csv', '/kaggle/working/labeled.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
